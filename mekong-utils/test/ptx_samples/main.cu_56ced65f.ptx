//
// Generated by LLVM NVPTX Back-End
//

.version 3.2
.target sm_20
.address_size 64

	// .globl	_Z17ComputePhiMag_GPUPfS_S_i // -- Begin function _Z17ComputePhiMag_GPUPfS_S_i
.visible .const .align 4 .b8 ck[16384];
.const .align 4 .b8 __cudart_i2opi_f[24] = {65, 144, 67, 60, 153, 149, 98, 219, 192, 221, 52, 245, 209, 87, 39, 252, 41, 21, 68, 78, 110, 131, 249, 162};
                                        // @_Z17ComputePhiMag_GPUPfS_S_i
.visible .entry _Z17ComputePhiMag_GPUPfS_S_i(
	.param .u64 _Z17ComputePhiMag_GPUPfS_S_i_param_0,
	.param .u64 _Z17ComputePhiMag_GPUPfS_S_i_param_1,
	.param .u64 _Z17ComputePhiMag_GPUPfS_S_i_param_2,
	.param .u32 _Z17ComputePhiMag_GPUPfS_S_i_param_3
)
{
	.reg .pred 	%p<2>;
	.reg .f32 	%f<5>;
	.reg .b32 	%r<6>;
	.reg .b64 	%rd<11>;

// %bb.0:                               // %entry
	ld.param.u32 	%r2, [_Z17ComputePhiMag_GPUPfS_S_i_param_3];
	mov.u32 	%r3, %ctaid.x;
	shl.b32 	%r4, %r3, 9;
	mov.u32 	%r5, %tid.x;
	add.s32 	%r1, %r4, %r5;
	setp.ge.s32 	%p1, %r1, %r2;
	@%p1 bra 	LBB0_2;
// %bb.1:                               // %if.then
	ld.param.u64 	%rd4, [_Z17ComputePhiMag_GPUPfS_S_i_param_0];
	ld.param.u64 	%rd5, [_Z17ComputePhiMag_GPUPfS_S_i_param_2];
	cvta.to.global.u64 	%rd1, %rd5;
	ld.param.u64 	%rd6, [_Z17ComputePhiMag_GPUPfS_S_i_param_1];
	cvta.to.global.u64 	%rd2, %rd6;
	cvta.to.global.u64 	%rd3, %rd4;
	mul.wide.s32 	%rd7, %r1, 4;
	add.s64 	%rd8, %rd3, %rd7;
	ld.global.f32 	%f1, [%rd8];
	add.s64 	%rd9, %rd2, %rd7;
	ld.global.f32 	%f2, [%rd9];
	mul.rn.f32 	%f3, %f2, %f2;
	fma.rn.f32 	%f4, %f1, %f1, %f3;
	add.s64 	%rd10, %rd1, %rd7;
	st.global.f32 	[%rd10], %f4;
LBB0_2:                                 // %if.end
	ret;
                                        // -- End function
}
	// .globl	_Z12ComputeQ_GPUiiPfS_S_S_S_ // -- Begin function _Z12ComputeQ_GPUiiPfS_S_S_S_
.visible .entry _Z12ComputeQ_GPUiiPfS_S_S_S_(
	.param .u32 _Z12ComputeQ_GPUiiPfS_S_S_S__param_0,
	.param .u32 _Z12ComputeQ_GPUiiPfS_S_S_S__param_1,
	.param .u64 _Z12ComputeQ_GPUiiPfS_S_S_S__param_2,
	.param .u64 _Z12ComputeQ_GPUiiPfS_S_S_S__param_3,
	.param .u64 _Z12ComputeQ_GPUiiPfS_S_S_S__param_4,
	.param .u64 _Z12ComputeQ_GPUiiPfS_S_S_S__param_5,
	.param .u64 _Z12ComputeQ_GPUiiPfS_S_S_S__param_6
)                                       // @_Z12ComputeQ_GPUiiPfS_S_S_S_
{
	.local .align 4 .b8 	__local_depot1[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<72>;
	.reg .f32 	%f<192>;
	.reg .b32 	%r<501>;
	.reg .b64 	%rd<88>;

// %bb.0:                               // %entry
	mov.u64 	%SPL, __local_depot1;
	ld.param.u32 	%r483, [_Z12ComputeQ_GPUiiPfS_S_S_S__param_1];
	ld.param.u32 	%r101, [_Z12ComputeQ_GPUiiPfS_S_S_S__param_0];
	ld.param.u64 	%rd23, [_Z12ComputeQ_GPUiiPfS_S_S_S__param_6];
	cvta.to.global.u64 	%rd24, %rd23;
	ld.param.u64 	%rd25, [_Z12ComputeQ_GPUiiPfS_S_S_S__param_5];
	cvta.to.global.u64 	%rd26, %rd25;
	ld.param.u64 	%rd27, [_Z12ComputeQ_GPUiiPfS_S_S_S__param_2];
	ld.param.u64 	%rd28, [_Z12ComputeQ_GPUiiPfS_S_S_S__param_4];
	cvta.to.global.u64 	%rd29, %rd28;
	ld.param.u64 	%rd30, [_Z12ComputeQ_GPUiiPfS_S_S_S__param_3];
	cvta.to.global.u64 	%rd31, %rd30;
	cvta.to.global.u64 	%rd32, %rd27;
	add.u64 	%rd1, %SPL, 0;
	mov.u32 	%r104, %ctaid.x;
	shl.b32 	%r105, %r104, 8;
	mov.u32 	%r106, %tid.x;
	add.s32 	%r107, %r105, %r106;
	mul.wide.s32 	%rd34, %r107, 4;
	add.s64 	%rd35, %rd32, %rd34;
	ld.global.f32 	%f1, [%rd35];
	add.s64 	%rd36, %rd31, %rd34;
	ld.global.f32 	%f2, [%rd36];
	add.s64 	%rd37, %rd29, %rd34;
	ld.global.f32 	%f3, [%rd37];
	add.s64 	%rd2, %rd26, %rd34;
	ld.global.f32 	%f191, [%rd2];
	add.s64 	%rd3, %rd24, %rd34;
	ld.global.f32 	%f190, [%rd3];
	and.b32  	%r108, %r101, 1;
	setp.eq.b32 	%p1, %r108, 1;
	mov.pred 	%p2, 0;
	xor.pred  	%p3, %p1, %p2;
	not.pred 	%p4, %p3;
	mov.u32 	%r484, 0;
	@%p4 bra 	LBB1_14;
// %bb.1:                               // %if.then
	ld.const.f32 	%f48, [ck];
	ld.const.f32 	%f49, [ck+4];
	mul.rn.f32 	%f50, %f2, %f49;
	fma.rn.f32 	%f51, %f1, %f48, %f50;
	ld.const.f32 	%f52, [ck+8];
	fma.rn.f32 	%f53, %f3, %f52, %f51;
	mul.rn.f32 	%f54, %f53, 0f40C90FDB;
	ld.const.f32 	%f6, [ck+12];
	abs.f32 	%f55, %f54;
	setp.eq.f32 	%p5, %f55, 0f7F800000;
	mul.rn.f32 	%f56, %f54, 0f00000000;
	selp.f32 	%f7, %f56, %f54, %p5;
	mul.rn.f32 	%f57, %f7, 0f3F22F983;
	cvt.rni.s32.f32 	%r480, %f57;
	cvt.rn.f32.s32 	%f58, %r480;
	fma.rn.f32 	%f59, %f58, 0fBFC90FDA, %f7;
	fma.rn.f32 	%f60, %f58, 0fB3A22168, %f59;
	fma.rn.f32 	%f179, %f58, 0fA7C234C5, %f60;
	abs.f32 	%f9, %f7;
	setp.leu.f32 	%p6, %f9, 0f47CE4780;
	mov.f32 	%f177, %f6;
	mov.f32 	%f178, %f179;
	mov.u32 	%r476, %r480;
	@%p6 bra 	LBB1_7;
// %bb.2:
	mov.b32 	%r2, %f7;
	shl.b32 	%r110, %r2, 8;
	or.b32  	%r114, %r110, -2147483648;
	mov.u32 	%r473, 0;
	mov.u64 	%rd82, 0;
	mov.u64 	%rd39, __cudart_i2opi_f;
LBB1_3:                                 // =>This Inner Loop Header: Depth=1
	.pragma "nounroll";
	add.s64 	%rd40, %rd39, %rd82;
	ld.const.u32 	%r113, [%rd40];
	// begin inline asm
	{
	mad.lo.cc.u32   %r111, %r113, %r114, %r473;
	madc.hi.u32     %r473, %r113, %r114,  0;
	}
	// end inline asm
	add.s64 	%rd41, %rd1, %rd82;
	st.local.u32 	[%rd41], %r111;
	add.s64 	%rd82, %rd82, 4;
	cvt.u32.u64 	%r116, %rd82;
	setp.ne.s32 	%p7, %r116, 24;
	@%p7 bra 	LBB1_3;
// %bb.4:
	bfe.u32 	%r117, %r2, 23, 8;
	add.s32 	%r118, %r117, -128;
	shr.u32 	%r119, %r118, 5;
	and.b32  	%r6, %r2, -2147483648;
	mul.wide.u32 	%rd42, %r119, 4;
	sub.s64 	%rd43, %rd1, %rd42;
	st.local.u32 	[%rd1+24], %r473;
	and.b32  	%r120, %r118, 31;
	ld.local.u32 	%r474, [%rd43+24];
	mul.wide.s32 	%rd44, %r119, 4;
	sub.s64 	%rd6, %rd1, %rd44;
	ld.local.u32 	%r475, [%rd6+20];
	setp.eq.s32 	%p8, %r120, 0;
	mov.u32 	%r121, 32;
	@%p8 bra 	LBB1_6;
// %bb.5:
	sub.s32 	%r9, %r121, %r120;
	shr.u32 	%r122, %r475, %r9;
	shl.b32 	%r123, %r474, %r120;
	add.s32 	%r474, %r122, %r123;
	shl.b32 	%r11, %r475, %r120;
	ld.local.u32 	%r124, [%rd6+16];
	shr.u32 	%r125, %r124, %r9;
	add.s32 	%r475, %r125, %r11;
LBB1_6:                                 // %__internal_trig_reduction_slowpath.exit.i.i.i.i.i169
	shr.u32 	%r126, %r474, 30;
	shl.b32 	%r127, %r474, 2;
	shr.u32 	%r128, %r475, 30;
	or.b32  	%r129, %r128, %r127;
	shl.b32 	%r130, %r475, 2;
	bfe.u32 	%r131, %r474, 29, 1;
	add.s32 	%r132, %r131, %r126;
	setp.eq.s32 	%p9, %r6, 0;
	neg.s32 	%r133, %r132;
	selp.b32 	%r476, %r132, %r133, %p9;
	setp.eq.s32 	%p10, %r131, 0;
	not.b32 	%r134, %r129;
	neg.s32 	%r135, %r130;
	setp.eq.s32 	%p11, %r130, 0;
	selp.u32 	%r136, 1, 0, %p11;
	add.s32 	%r137, %r136, %r134;
	xor.b32  	%r138, %r6, -2147483648;
	selp.b32 	%r139, %r129, %r137, %p10;
	selp.b32 	%r140, %r6, %r138, %p10;
	selp.b32 	%r141, %r130, %r135, %p10;
	clz.b32 	%r142, %r139;
	setp.eq.s32 	%p12, %r142, 0;
	shl.b32 	%r143, %r139, %r142;
	sub.s32 	%r145, %r121, %r142;
	shr.u32 	%r146, %r141, %r145;
	add.s32 	%r147, %r146, %r143;
	selp.b32 	%r148, %r139, %r147, %p12;
	mov.u32 	%r149, -921707870;
	mul.hi.u32 	%r150, %r148, %r149;
	setp.gt.s32 	%p13, %r150, 0;
	mul.lo.s32 	%r151, %r148, -921707870;
	shl.b32 	%r152, %r150, 1;
	shr.u32 	%r153, %r151, 31;
	or.b32  	%r154, %r153, %r152;
	selp.b32 	%r155, %r154, %r150, %p13;
	selp.u32 	%r156, 1, 0, %p13;
	add.s32 	%r157, %r142, %r156;
	shl.b32 	%r158, %r157, 23;
	mov.u32 	%r159, 1056964608;
	sub.s32 	%r160, %r159, %r158;
	add.s32 	%r161, %r155, 1;
	shr.u32 	%r162, %r161, 7;
	add.s32 	%r163, %r162, 1;
	shr.u32 	%r164, %r163, 1;
	add.s32 	%r165, %r160, %r164;
	or.b32  	%r166, %r165, %r140;
	mov.b32 	%f178, %r166;
	ld.const.f32 	%f177, [ck+12];
LBB1_7:                                 // %_ZL3cosf.exit176
	add.s32 	%r167, %r476, 1;
	mul.rn.f32 	%f61, %f178, %f178;
	and.b32  	%r168, %r167, 1;
	setp.eq.b32 	%p15, %r168, 1;
	fma.rn.f32 	%f62, %f61, 0f37CCF5CE, 0fBAB6061A;
	fma.rn.f32 	%f63, %f61, 0fB94CA1F9, 0f3C08839E;
	selp.f32 	%f64, %f62, %f63, %p15;
	fma.rn.f32 	%f65, %f64, %f61, 0f3D2AAAA5;
	fma.rn.f32 	%f66, %f65, %f61, 0fBF000000;
	fma.rn.f32 	%f67, %f64, %f61, 0fBE2AAAA3;
	fma.rn.f32 	%f68, %f67, %f61, 0f00000000;
	selp.f32 	%f69, %f66, %f68, %p15;
	fma.rn.f32 	%f70, %f69, %f178, %f178;
	fma.rn.f32 	%f71, %f69, %f61, 0f3F800000;
	selp.f32 	%f72, %f71, %f70, %p15;
	and.b32  	%r169, %r167, 2;
	setp.eq.s32 	%p16, %r169, 0;
	mov.f32 	%f73, 0f00000000;
	sub.rn.f32 	%f74, %f73, %f72;
	selp.f32 	%f75, %f72, %f74, %p16;
	@%p6 bra 	LBB1_13;
// %bb.8:
	mov.b32 	%r17, %f7;
	shl.b32 	%r171, %r17, 8;
	or.b32  	%r175, %r171, -2147483648;
	mov.u32 	%r477, 0;
	mov.u64 	%rd83, 0;
	mov.u64 	%rd46, __cudart_i2opi_f;
LBB1_9:                                 // =>This Inner Loop Header: Depth=1
	.pragma "nounroll";
	add.s64 	%rd47, %rd46, %rd83;
	ld.const.u32 	%r174, [%rd47];
	// begin inline asm
	{
	mad.lo.cc.u32   %r172, %r174, %r175, %r477;
	madc.hi.u32     %r477, %r174, %r175,  0;
	}
	// end inline asm
	add.s64 	%rd48, %rd1, %rd83;
	st.local.u32 	[%rd48], %r172;
	add.s64 	%rd83, %rd83, 4;
	cvt.u32.u64 	%r177, %rd83;
	setp.ne.s32 	%p17, %r177, 24;
	@%p17 bra 	LBB1_9;
// %bb.10:
	bfe.u32 	%r178, %r17, 23, 8;
	add.s32 	%r179, %r178, -128;
	shr.u32 	%r180, %r179, 5;
	and.b32  	%r21, %r17, -2147483648;
	mul.wide.u32 	%rd49, %r180, 4;
	sub.s64 	%rd50, %rd1, %rd49;
	st.local.u32 	[%rd1+24], %r477;
	and.b32  	%r181, %r179, 31;
	ld.local.u32 	%r478, [%rd50+24];
	mul.wide.s32 	%rd51, %r180, 4;
	sub.s64 	%rd9, %rd1, %rd51;
	ld.local.u32 	%r479, [%rd9+20];
	setp.eq.s32 	%p18, %r181, 0;
	mov.u32 	%r182, 32;
	@%p18 bra 	LBB1_12;
// %bb.11:
	sub.s32 	%r24, %r182, %r181;
	shr.u32 	%r183, %r479, %r24;
	shl.b32 	%r184, %r478, %r181;
	add.s32 	%r478, %r183, %r184;
	shl.b32 	%r26, %r479, %r181;
	ld.local.u32 	%r185, [%rd9+16];
	shr.u32 	%r186, %r185, %r24;
	add.s32 	%r479, %r186, %r26;
LBB1_12:                                // %__internal_trig_reduction_slowpath.exit.i.i.i.i.i191
	shr.u32 	%r187, %r478, 30;
	shl.b32 	%r188, %r478, 2;
	shr.u32 	%r189, %r479, 30;
	or.b32  	%r190, %r189, %r188;
	shl.b32 	%r191, %r479, 2;
	bfe.u32 	%r192, %r478, 29, 1;
	add.s32 	%r193, %r192, %r187;
	setp.eq.s32 	%p19, %r21, 0;
	neg.s32 	%r194, %r193;
	selp.b32 	%r480, %r193, %r194, %p19;
	setp.eq.s32 	%p20, %r192, 0;
	not.b32 	%r195, %r190;
	neg.s32 	%r196, %r191;
	setp.eq.s32 	%p21, %r191, 0;
	selp.u32 	%r197, 1, 0, %p21;
	add.s32 	%r198, %r197, %r195;
	xor.b32  	%r199, %r21, -2147483648;
	selp.b32 	%r200, %r190, %r198, %p20;
	selp.b32 	%r201, %r21, %r199, %p20;
	selp.b32 	%r202, %r191, %r196, %p20;
	clz.b32 	%r203, %r200;
	setp.eq.s32 	%p22, %r203, 0;
	shl.b32 	%r204, %r200, %r203;
	sub.s32 	%r206, %r182, %r203;
	shr.u32 	%r207, %r202, %r206;
	add.s32 	%r208, %r207, %r204;
	selp.b32 	%r209, %r200, %r208, %p22;
	mov.u32 	%r210, -921707870;
	mul.hi.u32 	%r211, %r209, %r210;
	setp.gt.s32 	%p23, %r211, 0;
	mul.lo.s32 	%r212, %r209, -921707870;
	shl.b32 	%r213, %r211, 1;
	shr.u32 	%r214, %r212, 31;
	or.b32  	%r215, %r214, %r213;
	selp.b32 	%r216, %r215, %r211, %p23;
	selp.u32 	%r217, 1, 0, %p23;
	add.s32 	%r218, %r203, %r217;
	shl.b32 	%r219, %r218, 23;
	mov.u32 	%r220, 1056964608;
	sub.s32 	%r221, %r220, %r219;
	add.s32 	%r222, %r216, 1;
	shr.u32 	%r223, %r222, 7;
	add.s32 	%r224, %r223, 1;
	shr.u32 	%r225, %r224, 1;
	add.s32 	%r226, %r221, %r225;
	or.b32  	%r227, %r226, %r201;
	mov.b32 	%f179, %r227;
LBB1_13:                                // %_ZL3sinf.exit198
	fma.rn.f32 	%f191, %f6, %f75, %f191;
	mul.rn.f32 	%f76, %f179, %f179;
	and.b32  	%r229, %r480, 1;
	setp.eq.b32 	%p24, %r229, 1;
	fma.rn.f32 	%f77, %f76, 0f37CCF5CE, 0fBAB6061A;
	fma.rn.f32 	%f78, %f76, 0fB94CA1F9, 0f3C08839E;
	selp.f32 	%f79, %f77, %f78, %p24;
	fma.rn.f32 	%f80, %f79, %f76, 0f3D2AAAA5;
	fma.rn.f32 	%f81, %f80, %f76, 0fBF000000;
	fma.rn.f32 	%f82, %f79, %f76, 0fBE2AAAA3;
	fma.rn.f32 	%f83, %f82, %f76, 0f00000000;
	selp.f32 	%f84, %f81, %f83, %p24;
	fma.rn.f32 	%f85, %f84, %f179, %f179;
	fma.rn.f32 	%f86, %f84, %f76, 0f3F800000;
	selp.f32 	%f87, %f86, %f85, %p24;
	and.b32  	%r230, %r480, 2;
	setp.eq.s32 	%p25, %r230, 0;
	sub.rn.f32 	%f89, %f73, %f87;
	selp.f32 	%f90, %f87, %f89, %p25;
	fma.rn.f32 	%f190, %f177, %f90, %f190;
	add.s32 	%r483, %r483, 1;
	mov.u32 	%r484, 1;
LBB1_14:                                // %if.end
	setp.ge.s32 	%p26, %r483, %r101;
	@%p26 bra 	LBB1_41;
// %bb.15:                              // %for.body.lr.ph
	mov.u64 	%rd53, ck;
	mov.u64 	%rd54, 0;
	mov.u64 	%rd55, __cudart_i2opi_f;
LBB1_16:                                // %for.body
                                        // =>This Loop Header: Depth=1
                                        //     Child Loop BB1_18 Depth 2
                                        //     Child Loop BB1_24 Depth 2
                                        //     Child Loop BB1_30 Depth 2
                                        //     Child Loop BB1_36 Depth 2
	mul.wide.u32 	%rd52, %r484, 16;
	add.s64 	%rd10, %rd53, %rd52;
	ld.const.f32 	%f91, [%rd10];
	ld.const.f32 	%f92, [%rd10+4];
	mul.rn.f32 	%f93, %f2, %f92;
	fma.rn.f32 	%f94, %f1, %f91, %f93;
	ld.const.f32 	%f95, [%rd10+8];
	fma.rn.f32 	%f96, %f3, %f95, %f94;
	mul.rn.f32 	%f97, %f96, 0f40C90FDB;
	ld.const.f32 	%f22, [%rd10+12];
	abs.f32 	%f98, %f97;
	setp.eq.f32 	%p27, %f98, 0f7F800000;
	mul.rn.f32 	%f99, %f97, 0f00000000;
	selp.f32 	%f23, %f99, %f97, %p27;
	mul.rn.f32 	%f100, %f23, 0f3F22F983;
	cvt.rni.s32.f32 	%r492, %f100;
	cvt.rn.f32.s32 	%f101, %r492;
	fma.rn.f32 	%f102, %f101, 0fBFC90FDA, %f23;
	fma.rn.f32 	%f103, %f101, 0fB3A22168, %f102;
	fma.rn.f32 	%f186, %f101, 0fA7C234C5, %f103;
	abs.f32 	%f25, %f23;
	setp.leu.f32 	%p28, %f25, 0f47CE4780;
	mov.f32 	%f184, %f22;
	mov.f32 	%f185, %f186;
	mov.u32 	%r488, %r492;
	@%p28 bra 	LBB1_22;
// %bb.17:                              //   in Loop: Header=BB1_16 Depth=1
	mov.b32 	%r38, %f23;
	shl.b32 	%r232, %r38, 8;
	or.b32  	%r39, %r232, -2147483648;
	mov.u32 	%r485, 0;
	mov.u64 	%rd84, %rd54;
LBB1_18:                                //   Parent Loop BB1_16 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	.pragma "nounroll";
	add.s64 	%rd56, %rd55, %rd84;
	ld.const.u32 	%r235, [%rd56];
	// begin inline asm
	{
	mad.lo.cc.u32   %r233, %r235, %r39, %r485;
	madc.hi.u32     %r485, %r235, %r39,  0;
	}
	// end inline asm
	add.s64 	%rd57, %rd1, %rd84;
	st.local.u32 	[%rd57], %r233;
	add.s64 	%rd84, %rd84, 4;
	cvt.u32.u64 	%r238, %rd84;
	setp.ne.s32 	%p29, %r238, 24;
	@%p29 bra 	LBB1_18;
// %bb.19:                              //   in Loop: Header=BB1_16 Depth=1
	bfe.u32 	%r239, %r38, 23, 8;
	add.s32 	%r240, %r239, -128;
	shr.u32 	%r241, %r240, 5;
	and.b32  	%r42, %r38, -2147483648;
	mul.wide.u32 	%rd58, %r241, 4;
	sub.s64 	%rd59, %rd1, %rd58;
	st.local.u32 	[%rd1+24], %r485;
	and.b32  	%r242, %r240, 31;
	ld.local.u32 	%r486, [%rd59+24];
	mul.wide.s32 	%rd60, %r241, 4;
	sub.s64 	%rd13, %rd1, %rd60;
	ld.local.u32 	%r487, [%rd13+20];
	setp.eq.s32 	%p30, %r242, 0;
	mov.u32 	%r243, 32;
	@%p30 bra 	LBB1_21;
// %bb.20:                              //   in Loop: Header=BB1_16 Depth=1
	sub.s32 	%r45, %r243, %r242;
	shr.u32 	%r244, %r487, %r45;
	shl.b32 	%r245, %r486, %r242;
	add.s32 	%r486, %r244, %r245;
	shl.b32 	%r47, %r487, %r242;
	ld.local.u32 	%r246, [%rd13+16];
	shr.u32 	%r247, %r246, %r45;
	add.s32 	%r487, %r247, %r47;
LBB1_21:                                // %__internal_trig_reduction_slowpath.exit.i.i.i.i.i213
                                        //   in Loop: Header=BB1_16 Depth=1
	shr.u32 	%r248, %r486, 30;
	shl.b32 	%r249, %r486, 2;
	shr.u32 	%r250, %r487, 30;
	or.b32  	%r251, %r250, %r249;
	shl.b32 	%r252, %r487, 2;
	bfe.u32 	%r253, %r486, 29, 1;
	add.s32 	%r254, %r253, %r248;
	setp.eq.s32 	%p31, %r42, 0;
	neg.s32 	%r255, %r254;
	selp.b32 	%r488, %r254, %r255, %p31;
	setp.eq.s32 	%p32, %r253, 0;
	not.b32 	%r256, %r251;
	neg.s32 	%r257, %r252;
	setp.eq.s32 	%p33, %r252, 0;
	selp.u32 	%r258, 1, 0, %p33;
	add.s32 	%r259, %r258, %r256;
	xor.b32  	%r260, %r42, -2147483648;
	selp.b32 	%r261, %r251, %r259, %p32;
	selp.b32 	%r262, %r42, %r260, %p32;
	selp.b32 	%r263, %r252, %r257, %p32;
	clz.b32 	%r264, %r261;
	setp.eq.s32 	%p34, %r264, 0;
	shl.b32 	%r265, %r261, %r264;
	sub.s32 	%r267, %r243, %r264;
	shr.u32 	%r268, %r263, %r267;
	add.s32 	%r269, %r268, %r265;
	selp.b32 	%r270, %r261, %r269, %p34;
	mov.u32 	%r271, -921707870;
	mul.hi.u32 	%r272, %r270, %r271;
	setp.gt.s32 	%p35, %r272, 0;
	mul.lo.s32 	%r273, %r270, -921707870;
	shl.b32 	%r274, %r272, 1;
	shr.u32 	%r275, %r273, 31;
	or.b32  	%r276, %r275, %r274;
	selp.b32 	%r277, %r276, %r272, %p35;
	selp.u32 	%r278, 1, 0, %p35;
	add.s32 	%r279, %r264, %r278;
	shl.b32 	%r280, %r279, 23;
	mov.u32 	%r281, 1056964608;
	sub.s32 	%r282, %r281, %r280;
	add.s32 	%r283, %r277, 1;
	shr.u32 	%r284, %r283, 7;
	add.s32 	%r285, %r284, 1;
	shr.u32 	%r286, %r285, 1;
	add.s32 	%r287, %r282, %r286;
	or.b32  	%r288, %r287, %r262;
	mov.b32 	%f185, %r288;
	ld.const.f32 	%f184, [%rd10+12];
LBB1_22:                                // %_ZL3cosf.exit220
                                        //   in Loop: Header=BB1_16 Depth=1
	add.s32 	%r289, %r488, 1;
	mul.rn.f32 	%f104, %f185, %f185;
	and.b32  	%r290, %r289, 1;
	setp.eq.b32 	%p37, %r290, 1;
	fma.rn.f32 	%f105, %f104, 0f37CCF5CE, 0fBAB6061A;
	fma.rn.f32 	%f106, %f104, 0fB94CA1F9, 0f3C08839E;
	selp.f32 	%f107, %f105, %f106, %p37;
	fma.rn.f32 	%f108, %f107, %f104, 0f3D2AAAA5;
	fma.rn.f32 	%f109, %f108, %f104, 0fBF000000;
	fma.rn.f32 	%f110, %f107, %f104, 0fBE2AAAA3;
	fma.rn.f32 	%f111, %f110, %f104, 0f00000000;
	selp.f32 	%f112, %f109, %f111, %p37;
	fma.rn.f32 	%f113, %f112, %f185, %f185;
	fma.rn.f32 	%f114, %f112, %f104, 0f3F800000;
	selp.f32 	%f115, %f114, %f113, %p37;
	and.b32  	%r291, %r289, 2;
	setp.eq.s32 	%p38, %r291, 0;
	mov.f32 	%f116, 0f00000000;
	sub.rn.f32 	%f117, %f116, %f115;
	@%p28 bra 	LBB1_28;
// %bb.23:                              //   in Loop: Header=BB1_16 Depth=1
	mov.b32 	%r53, %f23;
	shl.b32 	%r293, %r53, 8;
	or.b32  	%r54, %r293, -2147483648;
	mov.u32 	%r489, 0;
	mov.u64 	%rd85, 0;
LBB1_24:                                //   Parent Loop BB1_16 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	.pragma "nounroll";
	add.s64 	%rd63, %rd55, %rd85;
	ld.const.u32 	%r296, [%rd63];
	// begin inline asm
	{
	mad.lo.cc.u32   %r294, %r296, %r54, %r489;
	madc.hi.u32     %r489, %r296, %r54,  0;
	}
	// end inline asm
	add.s64 	%rd64, %rd1, %rd85;
	st.local.u32 	[%rd64], %r294;
	add.s64 	%rd85, %rd85, 4;
	cvt.u32.u64 	%r299, %rd85;
	setp.ne.s32 	%p39, %r299, 24;
	@%p39 bra 	LBB1_24;
// %bb.25:                              //   in Loop: Header=BB1_16 Depth=1
	bfe.u32 	%r300, %r53, 23, 8;
	add.s32 	%r301, %r300, -128;
	shr.u32 	%r302, %r301, 5;
	and.b32  	%r57, %r53, -2147483648;
	mul.wide.u32 	%rd65, %r302, 4;
	sub.s64 	%rd66, %rd1, %rd65;
	st.local.u32 	[%rd1+24], %r489;
	and.b32  	%r303, %r301, 31;
	ld.local.u32 	%r490, [%rd66+24];
	mul.wide.s32 	%rd67, %r302, 4;
	sub.s64 	%rd16, %rd1, %rd67;
	ld.local.u32 	%r491, [%rd16+20];
	setp.eq.s32 	%p40, %r303, 0;
	mov.u32 	%r304, 32;
	@%p40 bra 	LBB1_27;
// %bb.26:                              //   in Loop: Header=BB1_16 Depth=1
	sub.s32 	%r60, %r304, %r303;
	shr.u32 	%r305, %r491, %r60;
	shl.b32 	%r306, %r490, %r303;
	add.s32 	%r490, %r305, %r306;
	shl.b32 	%r62, %r491, %r303;
	ld.local.u32 	%r307, [%rd16+16];
	shr.u32 	%r308, %r307, %r60;
	add.s32 	%r491, %r308, %r62;
LBB1_27:                                // %__internal_trig_reduction_slowpath.exit.i.i.i.i.i235
                                        //   in Loop: Header=BB1_16 Depth=1
	shr.u32 	%r309, %r490, 30;
	shl.b32 	%r310, %r490, 2;
	shr.u32 	%r311, %r491, 30;
	or.b32  	%r312, %r311, %r310;
	shl.b32 	%r313, %r491, 2;
	bfe.u32 	%r314, %r490, 29, 1;
	add.s32 	%r315, %r314, %r309;
	setp.eq.s32 	%p41, %r57, 0;
	neg.s32 	%r316, %r315;
	selp.b32 	%r492, %r315, %r316, %p41;
	setp.eq.s32 	%p42, %r314, 0;
	not.b32 	%r317, %r312;
	neg.s32 	%r318, %r313;
	setp.eq.s32 	%p43, %r313, 0;
	selp.u32 	%r319, 1, 0, %p43;
	add.s32 	%r320, %r319, %r317;
	xor.b32  	%r321, %r57, -2147483648;
	selp.b32 	%r322, %r312, %r320, %p42;
	selp.b32 	%r323, %r57, %r321, %p42;
	selp.b32 	%r324, %r313, %r318, %p42;
	clz.b32 	%r325, %r322;
	setp.eq.s32 	%p44, %r325, 0;
	shl.b32 	%r326, %r322, %r325;
	sub.s32 	%r328, %r304, %r325;
	shr.u32 	%r329, %r324, %r328;
	add.s32 	%r330, %r329, %r326;
	selp.b32 	%r331, %r322, %r330, %p44;
	mov.u32 	%r332, -921707870;
	mul.hi.u32 	%r333, %r331, %r332;
	setp.gt.s32 	%p45, %r333, 0;
	mul.lo.s32 	%r334, %r331, -921707870;
	shl.b32 	%r335, %r333, 1;
	shr.u32 	%r336, %r334, 31;
	or.b32  	%r337, %r336, %r335;
	selp.b32 	%r338, %r337, %r333, %p45;
	selp.u32 	%r339, 1, 0, %p45;
	add.s32 	%r340, %r325, %r339;
	shl.b32 	%r341, %r340, 23;
	mov.u32 	%r342, 1056964608;
	sub.s32 	%r343, %r342, %r341;
	add.s32 	%r344, %r338, 1;
	shr.u32 	%r345, %r344, 7;
	add.s32 	%r346, %r345, 1;
	shr.u32 	%r347, %r346, 1;
	add.s32 	%r348, %r343, %r347;
	or.b32  	%r349, %r348, %r323;
	mov.b32 	%f186, %r349;
LBB1_28:                                // %_ZL3sinf.exit242
                                        //   in Loop: Header=BB1_16 Depth=1
	selp.f32 	%f118, %f115, %f117, %p38;
	mul.rn.f32 	%f119, %f186, %f186;
	and.b32  	%r350, %r492, 1;
	setp.eq.b32 	%p46, %r350, 1;
	fma.rn.f32 	%f120, %f119, 0f37CCF5CE, 0fBAB6061A;
	fma.rn.f32 	%f121, %f119, 0fB94CA1F9, 0f3C08839E;
	selp.f32 	%f122, %f120, %f121, %p46;
	fma.rn.f32 	%f123, %f122, %f119, 0f3D2AAAA5;
	fma.rn.f32 	%f124, %f123, %f119, 0fBF000000;
	fma.rn.f32 	%f125, %f122, %f119, 0fBE2AAAA3;
	fma.rn.f32 	%f126, %f125, %f119, 0f00000000;
	selp.f32 	%f127, %f124, %f126, %p46;
	fma.rn.f32 	%f128, %f127, %f186, %f186;
	fma.rn.f32 	%f129, %f127, %f119, 0f3F800000;
	selp.f32 	%f130, %f129, %f128, %p46;
	and.b32  	%r351, %r492, 2;
	setp.eq.s32 	%p47, %r351, 0;
	sub.rn.f32 	%f132, %f116, %f130;
	selp.f32 	%f133, %f130, %f132, %p47;
	ld.const.f32 	%f134, [%rd10+16];
	ld.const.f32 	%f135, [%rd10+20];
	mul.rn.f32 	%f136, %f2, %f135;
	fma.rn.f32 	%f137, %f1, %f134, %f136;
	ld.const.f32 	%f138, [%rd10+24];
	fma.rn.f32 	%f139, %f3, %f138, %f137;
	mul.rn.f32 	%f140, %f139, 0f40C90FDB;
	ld.const.f32 	%f34, [%rd10+28];
	abs.f32 	%f141, %f140;
	setp.eq.f32 	%p48, %f141, 0f7F800000;
	mul.rn.f32 	%f142, %f140, 0f00000000;
	selp.f32 	%f35, %f142, %f140, %p48;
	mul.rn.f32 	%f143, %f35, 0f3F22F983;
	cvt.rni.s32.f32 	%r500, %f143;
	cvt.rn.f32.s32 	%f144, %r500;
	fma.rn.f32 	%f145, %f144, 0fBFC90FDA, %f35;
	fma.rn.f32 	%f146, %f144, 0fB3A22168, %f145;
	fma.rn.f32 	%f189, %f144, 0fA7C234C5, %f146;
	abs.f32 	%f37, %f35;
	setp.leu.f32 	%p49, %f37, 0f47CE4780;
	mov.f32 	%f187, %f34;
	mov.f32 	%f188, %f189;
	mov.u32 	%r496, %r500;
	@%p49 bra 	LBB1_34;
// %bb.29:                              //   in Loop: Header=BB1_16 Depth=1
	mov.b32 	%r69, %f35;
	shl.b32 	%r353, %r69, 8;
	or.b32  	%r70, %r353, -2147483648;
	mov.u32 	%r493, 0;
	mov.u64 	%rd86, 0;
LBB1_30:                                //   Parent Loop BB1_16 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	.pragma "nounroll";
	add.s64 	%rd70, %rd55, %rd86;
	ld.const.u32 	%r356, [%rd70];
	// begin inline asm
	{
	mad.lo.cc.u32   %r354, %r356, %r70, %r493;
	madc.hi.u32     %r493, %r356, %r70,  0;
	}
	// end inline asm
	add.s64 	%rd71, %rd1, %rd86;
	st.local.u32 	[%rd71], %r354;
	add.s64 	%rd86, %rd86, 4;
	cvt.u32.u64 	%r359, %rd86;
	setp.ne.s32 	%p50, %r359, 24;
	@%p50 bra 	LBB1_30;
// %bb.31:                              //   in Loop: Header=BB1_16 Depth=1
	bfe.u32 	%r360, %r69, 23, 8;
	add.s32 	%r361, %r360, -128;
	shr.u32 	%r362, %r361, 5;
	and.b32  	%r73, %r69, -2147483648;
	mul.wide.u32 	%rd72, %r362, 4;
	sub.s64 	%rd73, %rd1, %rd72;
	st.local.u32 	[%rd1+24], %r493;
	and.b32  	%r363, %r361, 31;
	ld.local.u32 	%r494, [%rd73+24];
	mul.wide.s32 	%rd74, %r362, 4;
	sub.s64 	%rd19, %rd1, %rd74;
	ld.local.u32 	%r495, [%rd19+20];
	setp.eq.s32 	%p51, %r363, 0;
	mov.u32 	%r364, 32;
	@%p51 bra 	LBB1_33;
// %bb.32:                              //   in Loop: Header=BB1_16 Depth=1
	sub.s32 	%r76, %r364, %r363;
	shr.u32 	%r365, %r495, %r76;
	shl.b32 	%r366, %r494, %r363;
	add.s32 	%r494, %r365, %r366;
	shl.b32 	%r78, %r495, %r363;
	ld.local.u32 	%r367, [%rd19+16];
	shr.u32 	%r368, %r367, %r76;
	add.s32 	%r495, %r368, %r78;
LBB1_33:                                // %__internal_trig_reduction_slowpath.exit.i.i.i.i.i148
                                        //   in Loop: Header=BB1_16 Depth=1
	shr.u32 	%r369, %r494, 30;
	shl.b32 	%r370, %r494, 2;
	shr.u32 	%r371, %r495, 30;
	or.b32  	%r372, %r371, %r370;
	shl.b32 	%r373, %r495, 2;
	bfe.u32 	%r374, %r494, 29, 1;
	add.s32 	%r375, %r374, %r369;
	setp.eq.s32 	%p52, %r73, 0;
	neg.s32 	%r376, %r375;
	selp.b32 	%r496, %r375, %r376, %p52;
	setp.eq.s32 	%p53, %r374, 0;
	not.b32 	%r377, %r372;
	neg.s32 	%r378, %r373;
	setp.eq.s32 	%p54, %r373, 0;
	selp.u32 	%r379, 1, 0, %p54;
	add.s32 	%r380, %r379, %r377;
	xor.b32  	%r381, %r73, -2147483648;
	selp.b32 	%r382, %r372, %r380, %p53;
	selp.b32 	%r383, %r73, %r381, %p53;
	selp.b32 	%r384, %r373, %r378, %p53;
	clz.b32 	%r385, %r382;
	setp.eq.s32 	%p55, %r385, 0;
	shl.b32 	%r386, %r382, %r385;
	sub.s32 	%r388, %r364, %r385;
	shr.u32 	%r389, %r384, %r388;
	add.s32 	%r390, %r389, %r386;
	selp.b32 	%r391, %r382, %r390, %p55;
	mov.u32 	%r392, -921707870;
	mul.hi.u32 	%r393, %r391, %r392;
	setp.gt.s32 	%p56, %r393, 0;
	mul.lo.s32 	%r394, %r391, -921707870;
	shl.b32 	%r395, %r393, 1;
	shr.u32 	%r396, %r394, 31;
	or.b32  	%r397, %r396, %r395;
	selp.b32 	%r398, %r397, %r393, %p56;
	selp.u32 	%r399, 1, 0, %p56;
	add.s32 	%r400, %r385, %r399;
	shl.b32 	%r401, %r400, 23;
	mov.u32 	%r402, 1056964608;
	sub.s32 	%r403, %r402, %r401;
	add.s32 	%r404, %r398, 1;
	shr.u32 	%r405, %r404, 7;
	add.s32 	%r406, %r405, 1;
	shr.u32 	%r407, %r406, 1;
	add.s32 	%r408, %r403, %r407;
	or.b32  	%r409, %r408, %r383;
	mov.b32 	%f188, %r409;
	ld.const.f32 	%f187, [%rd10+28];
LBB1_34:                                // %_ZL3cosf.exit
                                        //   in Loop: Header=BB1_16 Depth=1
	fma.rn.f32 	%f30, %f22, %f118, %f191;
	fma.rn.f32 	%f33, %f184, %f133, %f190;
	add.s32 	%r410, %r496, 1;
	mul.rn.f32 	%f147, %f188, %f188;
	and.b32  	%r411, %r410, 1;
	setp.eq.b32 	%p58, %r411, 1;
	fma.rn.f32 	%f148, %f147, 0f37CCF5CE, 0fBAB6061A;
	fma.rn.f32 	%f149, %f147, 0fB94CA1F9, 0f3C08839E;
	selp.f32 	%f150, %f148, %f149, %p58;
	fma.rn.f32 	%f151, %f150, %f147, 0f3D2AAAA5;
	fma.rn.f32 	%f152, %f151, %f147, 0fBF000000;
	fma.rn.f32 	%f153, %f150, %f147, 0fBE2AAAA3;
	fma.rn.f32 	%f154, %f153, %f147, 0f00000000;
	selp.f32 	%f155, %f152, %f154, %p58;
	fma.rn.f32 	%f156, %f155, %f188, %f188;
	fma.rn.f32 	%f157, %f155, %f147, 0f3F800000;
	selp.f32 	%f158, %f157, %f156, %p58;
	and.b32  	%r412, %r410, 2;
	setp.eq.s32 	%p59, %r412, 0;
	sub.rn.f32 	%f160, %f116, %f158;
	selp.f32 	%f161, %f158, %f160, %p59;
	@%p49 bra 	LBB1_40;
// %bb.35:                              //   in Loop: Header=BB1_16 Depth=1
	mov.b32 	%r84, %f35;
	shl.b32 	%r414, %r84, 8;
	or.b32  	%r85, %r414, -2147483648;
	mov.u32 	%r497, 0;
	mov.u64 	%rd87, 0;
LBB1_36:                                //   Parent Loop BB1_16 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	.pragma "nounroll";
	add.s64 	%rd77, %rd55, %rd87;
	ld.const.u32 	%r417, [%rd77];
	// begin inline asm
	{
	mad.lo.cc.u32   %r415, %r417, %r85, %r497;
	madc.hi.u32     %r497, %r417, %r85,  0;
	}
	// end inline asm
	add.s64 	%rd78, %rd1, %rd87;
	st.local.u32 	[%rd78], %r415;
	add.s64 	%rd87, %rd87, 4;
	cvt.u32.u64 	%r420, %rd87;
	setp.ne.s32 	%p60, %r420, 24;
	@%p60 bra 	LBB1_36;
// %bb.37:                              //   in Loop: Header=BB1_16 Depth=1
	bfe.u32 	%r421, %r84, 23, 8;
	add.s32 	%r422, %r421, -128;
	shr.u32 	%r423, %r422, 5;
	and.b32  	%r88, %r84, -2147483648;
	mul.wide.u32 	%rd79, %r423, 4;
	sub.s64 	%rd80, %rd1, %rd79;
	st.local.u32 	[%rd1+24], %r497;
	and.b32  	%r424, %r422, 31;
	ld.local.u32 	%r498, [%rd80+24];
	mul.wide.s32 	%rd81, %r423, 4;
	sub.s64 	%rd22, %rd1, %rd81;
	ld.local.u32 	%r499, [%rd22+20];
	setp.eq.s32 	%p61, %r424, 0;
	mov.u32 	%r425, 32;
	@%p61 bra 	LBB1_39;
// %bb.38:                              //   in Loop: Header=BB1_16 Depth=1
	sub.s32 	%r91, %r425, %r424;
	shr.u32 	%r426, %r499, %r91;
	shl.b32 	%r427, %r498, %r424;
	add.s32 	%r498, %r426, %r427;
	shl.b32 	%r93, %r499, %r424;
	ld.local.u32 	%r428, [%rd22+16];
	shr.u32 	%r429, %r428, %r91;
	add.s32 	%r499, %r429, %r93;
LBB1_39:                                // %__internal_trig_reduction_slowpath.exit.i.i.i.i.i
                                        //   in Loop: Header=BB1_16 Depth=1
	shr.u32 	%r430, %r498, 30;
	shl.b32 	%r431, %r498, 2;
	shr.u32 	%r432, %r499, 30;
	or.b32  	%r433, %r432, %r431;
	shl.b32 	%r434, %r499, 2;
	bfe.u32 	%r435, %r498, 29, 1;
	add.s32 	%r436, %r435, %r430;
	setp.eq.s32 	%p62, %r88, 0;
	neg.s32 	%r437, %r436;
	selp.b32 	%r500, %r436, %r437, %p62;
	setp.eq.s32 	%p63, %r435, 0;
	not.b32 	%r438, %r433;
	neg.s32 	%r439, %r434;
	setp.eq.s32 	%p64, %r434, 0;
	selp.u32 	%r440, 1, 0, %p64;
	add.s32 	%r441, %r440, %r438;
	xor.b32  	%r442, %r88, -2147483648;
	selp.b32 	%r443, %r433, %r441, %p63;
	selp.b32 	%r444, %r88, %r442, %p63;
	selp.b32 	%r445, %r434, %r439, %p63;
	clz.b32 	%r446, %r443;
	setp.eq.s32 	%p65, %r446, 0;
	shl.b32 	%r447, %r443, %r446;
	sub.s32 	%r449, %r425, %r446;
	shr.u32 	%r450, %r445, %r449;
	add.s32 	%r451, %r450, %r447;
	selp.b32 	%r452, %r443, %r451, %p65;
	mov.u32 	%r453, -921707870;
	mul.hi.u32 	%r454, %r452, %r453;
	setp.gt.s32 	%p66, %r454, 0;
	mul.lo.s32 	%r455, %r452, -921707870;
	shl.b32 	%r456, %r454, 1;
	shr.u32 	%r457, %r455, 31;
	or.b32  	%r458, %r457, %r456;
	selp.b32 	%r459, %r458, %r454, %p66;
	selp.u32 	%r460, 1, 0, %p66;
	add.s32 	%r461, %r446, %r460;
	shl.b32 	%r462, %r461, 23;
	mov.u32 	%r463, 1056964608;
	sub.s32 	%r464, %r463, %r462;
	add.s32 	%r465, %r459, 1;
	shr.u32 	%r466, %r465, 7;
	add.s32 	%r467, %r466, 1;
	shr.u32 	%r468, %r467, 1;
	add.s32 	%r469, %r464, %r468;
	or.b32  	%r470, %r469, %r444;
	mov.b32 	%f189, %r470;
LBB1_40:                                // %_ZL3sinf.exit
                                        //   in Loop: Header=BB1_16 Depth=1
	fma.rn.f32 	%f191, %f34, %f161, %f30;
	mul.rn.f32 	%f162, %f189, %f189;
	and.b32  	%r471, %r500, 1;
	setp.eq.b32 	%p67, %r471, 1;
	fma.rn.f32 	%f163, %f162, 0f37CCF5CE, 0fBAB6061A;
	fma.rn.f32 	%f164, %f162, 0fB94CA1F9, 0f3C08839E;
	selp.f32 	%f165, %f163, %f164, %p67;
	fma.rn.f32 	%f166, %f165, %f162, 0f3D2AAAA5;
	fma.rn.f32 	%f167, %f166, %f162, 0fBF000000;
	fma.rn.f32 	%f168, %f165, %f162, 0fBE2AAAA3;
	fma.rn.f32 	%f169, %f168, %f162, 0f00000000;
	selp.f32 	%f170, %f167, %f169, %p67;
	fma.rn.f32 	%f171, %f170, %f189, %f189;
	fma.rn.f32 	%f172, %f170, %f162, 0f3F800000;
	selp.f32 	%f173, %f172, %f171, %p67;
	and.b32  	%r472, %r500, 2;
	setp.eq.s32 	%p68, %r472, 0;
	sub.rn.f32 	%f175, %f116, %f173;
	selp.f32 	%f176, %f173, %f175, %p68;
	fma.rn.f32 	%f190, %f187, %f176, %f33;
	add.s32 	%r484, %r484, 2;
	add.s32 	%r483, %r483, 2;
	setp.lt.u32 	%p69, %r484, 1024;
	setp.lt.s32 	%p70, %r483, %r101;
	and.pred  	%p71, %p69, %p70;
	@%p71 bra 	LBB1_16;
LBB1_41:                                // %for.end
	st.global.f32 	[%rd2], %f191;
	st.global.f32 	[%rd3], %f190;
	ret;
                                        // -- End function
}

